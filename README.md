# 决策树实践实验室

这个项目实现了从零开始的决策树算法，用于分类蘑菇是否可食用。

## 项目概述

本项目是一个完整的决策树实现，包含以下核心功能：

1. **熵计算** - 计算节点的信息熵
2. **数据集分割** - 根据特征值分割数据集
3. **信息增益计算** - 计算分割后的信息增益
4. **最佳分割选择** - 选择提供最大信息增益的特征
5. **决策树构建** - 递归构建完整的决策树

## 文件结构

```
decision tree/
├── decision_tree_lab.py      # 主要的决策树实现
├── test_decision_tree.py     # 测试文件
├── utils.py                  # 工具函数和可视化
└── README.md                 # 项目说明文档
```

## 数据集

项目使用蘑菇数据集，包含10个样本，每个样本有3个特征：

- **特征0**: 棕色菌盖 (1=棕色, 0=红色)
- **特征1**: 锥形菌柄 (1=锥形, 0=扩大)  
- **特征2**: 独生 (1=是, 0=否)

标签：可食用(1) 或 有毒(0)

## 核心函数

### 1. `compute_entropy(y)`
计算节点的熵值：
```
H(p₁) = -p₁log₂(p₁) - (1-p₁)log₂(1-p₁)
```

### 2. `split_dataset(X, node_indices, feature)`
根据特征值分割数据集为左右两个分支。

### 3. `compute_information_gain(X, y, node_indices, feature)`
计算分割后的信息增益：
```
信息增益 = H(根节点) - (w左 × H(左分支) + w右 × H(右分支))
```

### 4. `get_best_split(X, y, node_indices)`
选择提供最大信息增益的最佳分割特征。

### 5. `build_tree_recursive(...)`
递归构建决策树，最大深度为2。

## 运行项目

### 运行主程序
```bash
python decision_tree_lab.py
```

### 运行测试
```bash
python test_decision_tree.py
```

### 使用可视化工具
```python
from utils import *
from decision_tree_lab import *

# 设置数据集
set_dataset(X_train, y_train)

# 绘制熵函数曲线
plot_entropy_curve()

# 绘制信息增益比较
plot_information_gain_comparison()

# 打印数据集摘要
print_dataset_summary()
```

## 预期输出

运行主程序后，您将看到：

1. **数据集信息** - 样本数量、特征数量、标签分布
2. **练习1结果** - 根节点熵值 (应为1.0)
3. **练习2结果** - 数据集分割示例
4. **练习3结果** - 各特征的信息增益
5. **练习4结果** - 最佳分割特征选择
6. **决策树结构** - 完整的树构建过程

## 算法原理

### 决策树构建步骤
1. 从根节点开始，包含所有训练样本
2. 计算每个特征的信息增益
3. 选择信息增益最大的特征进行分割
4. 递归地对子节点重复步骤2-3
5. 达到停止条件时停止（最大深度=2）

### 信息增益计算
- 熵衡量节点的不纯度
- 信息增益衡量分割后纯度的提升
- 选择信息增益最大的特征进行分割

## 测试验证

项目包含完整的测试套件，验证：
- 熵计算的正确性
- 数据集分割的准确性
- 信息增益计算的正确性
- 最佳特征选择的准确性
- 蘑菇数据集上的完整流程



## 许可证

本项目仅供学习和研究使用。
